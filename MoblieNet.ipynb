{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import torch.nn.functional as F\n",
    "from torch.utils import data\n",
    "import torch\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "indice1=300\n",
    "sample=32\n",
    "cl=16\n",
    "indice1 = 300\n",
    "\n",
    "train = np.load(\"train.npy\")\n",
    "train = torch.from_numpy(np.stack(train, 0))\n",
    "test = np.load(\"test.npy\")\n",
    "test = torch.from_numpy(np.stack(test, 0))\n",
    "valid = np.load(\"valid.npy\")\n",
    "valid = torch.from_numpy(np.stack(valid, 0))\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "print(valid.shape)\n",
    "\n",
    "label=np.arange(0,cl,1)\n",
    "label = label.astype(np.float32)\n",
    "train_label = torch.from_numpy(np.tile(label, indice1)) \n",
    "test_label  = torch.from_numpy(np.tile(label, 100))\n",
    "valid_label = torch.from_numpy(np.tile(label, 2))\n",
    "\n",
    "print(train_label.dtype)\n",
    "print(train_label.shape)\n",
    "print(test_label.shape)\n",
    "print(valid_label.shape)\n",
    "\n",
    "\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "train_dataset = TensorDataset(train, train_label)\n",
    "valid_dataset = TensorDataset(valid, valid_label)\n",
    "test_dataset = TensorDataset(test, test_label)\n",
    "batch=cl*2\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset = train_dataset,\n",
    "    batch_size = batch,            \n",
    "    shuffle= True,          \n",
    ")\n",
    "\n",
    "valid_loader = DataLoader(\n",
    "    dataset = valid_dataset,\n",
    "    batch_size = batch,           \n",
    "    shuffle= True,          \n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset = test_dataset,\n",
    "    batch_size = batch,     \n",
    "    shuffle= True,            \n",
    ")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([4800, 32, 204])\n",
      "torch.Size([1600, 32, 204])\n",
      "torch.Size([32, 32, 204])\n",
      "torch.float32\n",
      "torch.Size([4800])\n",
      "torch.Size([1600])\n",
      "torch.Size([32])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import argparse\n",
    "\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "from torch.utils import data\n",
    "import os\n",
    "import random\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Sequence Modeling')\n",
    "parser.add_argument('--batch_size', type=int, default=cl*2, metavar='N',\n",
    "                    help='batch size (default: 128)')\n",
    "parser.add_argument('--cuda', action='store_true', default=False,\n",
    "                    help='Disable cuda for training')\n",
    "parser.add_argument('--dropout', type=float, default=0.45,\n",
    "                    help='dropout applied to layers (default: 0.05)')\n",
    "parser.add_argument('--clip', type=float, default=0.35,\n",
    "                    help='gradient clip, -1 means no clip (default: -1)')\n",
    "parser.add_argument('--epochs', type=int, default=30,\n",
    "                    help='upper epoch limit (default: 20)')\n",
    "parser.add_argument('--levels', type=int, default=4,\n",
    "                    help='# of levels (default: 8)')\n",
    "parser.add_argument('--log-interval', type=int, default=1, metavar='N',\n",
    "                    help='report interval (default: 100')\n",
    "parser.add_argument('--lr', type=float, default=1e-4,\n",
    "                    help='initial learning rate (default: 2e-3)')\n",
    "parser.add_argument('--optim', type=str, default='Adam',\n",
    "                    help='optimizer to use (default: Adam)')\n",
    "parser.add_argument('--seed', type=int, default=1111,\n",
    "                    help='random seed (default: 1111)')\n",
    "parser.add_argument('--seq_len', type=int, default=204)\n",
    "\n",
    "args = parser.parse_args([])\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    if not args.cuda:\n",
    "        print(\"WARNING: You have a CUDA device, so you should probably run with --cuda\")\n",
    "print(args)\n",
    "\n",
    "torch.manual_seed(args.seed)\n",
    "batch_size = args.batch_size  \n",
    "print(batch_size)\n",
    "epochs = args.epochs \n",
    "input_channels = sample\n",
    "print(input_channels)\n",
    "channel_sizes = [input_channels*2] * args.levels   \n",
    "n_classes = cl\n",
    "print(n_classes)\n",
    "steps = 0\n",
    "\n",
    "\n",
    "import math\n",
    "from einops import rearrange\n",
    "from torch.nn import init\n",
    "from torch.nn.utils import weight_norm\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, s=64, p=64, l=204):\n",
    "        super(ConvNet, self).__init__()\n",
    "\n",
    "        self.tconv1 = weight_norm(nn.Conv1d(s, p, kernel_size=3,stride=1, padding=1, groups=s))\n",
    "        self.p1 = nn.Conv1d(p, p, kernel_size=1, stride=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.tconv2 = weight_norm(nn.Conv1d(p, p, kernel_size=3,stride=1, padding=1, groups=p))\n",
    "        self.p2 = nn.Conv1d(p, p, kernel_size=1, stride=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.tconv3 = weight_norm(nn.Conv1d(p, p, kernel_size=3,stride=1, padding=1, groups=p))\n",
    "        self.p3 = nn.Conv1d(p, p, kernel_size=1, stride=1)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.tconv4 = weight_norm(nn.Conv1d(p, p, kernel_size=3,stride=1, padding=1, groups=p))\n",
    "        self.p4 = nn.Conv1d(p, p, kernel_size=1, stride=1)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.ln0 = nn.LayerNorm([p,l],elementwise_affine = True)\n",
    "        self.init_weights()\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def init_weights(self):\n",
    "        self.tconv1.weight.data.normal_(0, 0.01)\n",
    "        self.tconv2.weight.data.normal_(0, 0.01)\n",
    "        self.tconv3.weight.data.normal_(0, 0.01)\n",
    "        self.tconv4.weight.data.normal_(0, 0.01)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        out_tcn1 = self.relu1(self.p1(self.tconv1(x)))\n",
    "        out_tcn2 = self.relu2(self.p2(self.tconv2(out_tcn1)))\n",
    "        out_tcn3 = self.relu3(self.p3(self.tconv3(out_tcn2)))\n",
    "        out = self.ln0(self.relu4(self.p4(self.tconv4(out_tcn3)))) \n",
    "        out =  self.relu(self.dropout(out))\n",
    "\n",
    "        return out\n",
    "class Moblienet(nn.Module):\n",
    "    def __init__(self, input_size, output_size,p,l):\n",
    "        super(Moblienet, self).__init__()\n",
    "\n",
    "        self.length=l\n",
    "        self.tcn = ConvNet(input_size,p,l)\n",
    "        self.linear = nn.Linear(l*4, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out= self.tcn(x)\n",
    "\n",
    "        y2 = F.adaptive_avg_pool2d(out.permute(0, 2, 1), [self.length,4])\n",
    "        y3 = y2.view(y2.size(0), -1)\n",
    "        o = self.linear(y3)\n",
    "\n",
    "        o = F.log_softmax(o, dim=1).contiguous()\n",
    "\n",
    "        return o"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Namespace(batch_size=32, cuda=False, dropout=0.45, clip=0.35, epochs=30, levels=4, log_interval=1, lr=0.0001, optim='Adam', seed=1111, seq_len=204)\n",
      "32\n",
      "32\n",
      "16\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "model = Moblienet(input_channels, n_classes, (sample//4)*8, 51*4)\n",
    "if args.cuda:\n",
    "    model.cuda()\n",
    "\n",
    "summary(model, input_size=[(input_channels, 204)], batch_size=batch_size)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1              [32, 64, 204]             256\n",
      "            Conv1d-2              [32, 64, 204]           4,160\n",
      "              ReLU-3              [32, 64, 204]               0\n",
      "            Conv1d-4              [32, 64, 204]             256\n",
      "            Conv1d-5              [32, 64, 204]           4,160\n",
      "              ReLU-6              [32, 64, 204]               0\n",
      "            Conv1d-7              [32, 64, 204]             256\n",
      "            Conv1d-8              [32, 64, 204]           4,160\n",
      "              ReLU-9              [32, 64, 204]               0\n",
      "           Conv1d-10              [32, 64, 204]             256\n",
      "           Conv1d-11              [32, 64, 204]           4,160\n",
      "             ReLU-12              [32, 64, 204]               0\n",
      "        LayerNorm-13              [32, 64, 204]          26,112\n",
      "          Dropout-14              [32, 64, 204]               0\n",
      "             ReLU-15              [32, 64, 204]               0\n",
      "          ConvNet-16              [32, 64, 204]               0\n",
      "           Linear-17                   [32, 16]          13,072\n",
      "================================================================\n",
      "Total params: 56,848\n",
      "Trainable params: 56,848\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.80\n",
      "Forward/backward pass size (MB): 51.00\n",
      "Params size (MB): 0.22\n",
      "Estimated Total Size (MB): 52.02\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "import torchmetrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "lr = args.lr\n",
    "optimizer = getattr(optim, args.optim)(model.parameters(), lr=lr)\n",
    "\n",
    "losses = []\n",
    "loss_test = []\n",
    "accuracy = []\n",
    "fm = []\n",
    "atts= []\n",
    "\n",
    "acc_valid = []\n",
    "\n",
    "\n",
    "def train(ep):\n",
    "    train_loss = 0\n",
    "    model.train()\n",
    "    for batch_idx, (bands, target) in enumerate(train_loader):\n",
    " #       if args.cuda: bands, target = bands.cuda(), target.cuda()\n",
    "        bands, target = Variable(bands), Variable(target)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(bands)\n",
    "        loss = F.nll_loss(output, target.long())\n",
    "        loss.backward()\n",
    "        if args.clip > 0:\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), args.clip)\n",
    "        optimizer.step()\n",
    "        train_loss += loss\n",
    "        if batch_idx % args.log_interval == 0:\n",
    "            los = train_loss.item()/args.log_interval\n",
    "            losses.append(los)\n",
    "            train_loss = 0\n",
    "\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    test_acc = torchmetrics.Accuracy()\n",
    "    test_fm = torchmetrics.ConfusionMatrix(threshold=1./16,num_classes=16)\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for bands, target in loader:\n",
    "#            if args.cuda: bands, target = bands.cuda(), target.cuda()\n",
    "            with torch.no_grad():\n",
    "                bands, target = Variable(bands), Variable(target)\n",
    "            pred = model(bands)\n",
    "            test_loss += F.nll_loss(pred, target.long()).item()\n",
    "            correct += (pred.argmax(1) == target.long()).type(torch.float).sum().item()\n",
    "            test_acc(pred.argmax(1), target.long())\n",
    "            test_fm(pred.argmax(1), target.long())\n",
    "\n",
    "    test_loss /= len(test_loader)\n",
    "    loss_test.append(test_loss)\n",
    "    correct /= len(test_loader.dataset)\n",
    "\n",
    "    total_acc = test_acc.compute()\n",
    "    total_acc = torch.mean(total_acc)\n",
    "    accuracy.append(total_acc)\n",
    "\n",
    "    total_fm = test_fm.compute()\n",
    "    fm.append(total_fm)\n",
    "\n",
    "       \n",
    "    print(f\"Accuracy: {(100 * correct):>0.1f}%, \"f\"Avg loss: {test_loss:>8f}, \"f\"torch metrics acc: {total_acc}%\")\n",
    "\n",
    "    test_fm.reset()\n",
    "\n",
    "    return test_loss\n",
    "\n",
    "def valid(loader):\n",
    "    model.eval()\n",
    "    test_acc = torchmetrics.Accuracy()\n",
    "    test_fm = torchmetrics.ConfusionMatrix(threshold=1./16,num_classes=16)\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for bands, target in loader:\n",
    "#            if args.cuda: bands, target = bands.cuda(), target.cuda()\n",
    "            with torch.no_grad():\n",
    "                bands, target = Variable(bands), Variable(target)\n",
    "            pred = model(bands)\n",
    "            test_loss += F.nll_loss(pred, target.long()).item()\n",
    "            correct += (pred.argmax(1) == target.long()).type(torch.float).sum().item()\n",
    "            test_acc(pred.argmax(1), target.long())\n",
    "            test_fm(pred.argmax(1), target.long())\n",
    "\n",
    "    test_loss /= len(test_loader)\n",
    "    correct /= len(test_loader.dataset)\n",
    "\n",
    "    total_acc = test_acc.compute()\n",
    "    acc_valid.append(total_acc)\n",
    "\n",
    "    total_fm = test_fm.compute()\n",
    "    fm.append(total_fm)\n",
    "       \n",
    "    print(f\"Valid Accuracy: {(100 * correct):>0.1f}%, \"f\"Avg loss: {test_loss:>8f}, \"f\"torch metrics acc: {total_acc}%\")\n",
    "\n",
    "    test_acc.reset()\n",
    "    test_fm.reset()\n",
    "\n",
    "    return test_loss\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    for epoch in range(1, epochs+1):\n",
    "        train(epoch)\n",
    "        if epoch%5==0:\n",
    "            print(\"Epoch: \",epoch)\n",
    "            print(\"TEST:\") \n",
    "            test(test_loader)\n",
    "#            print(\"VALID:\")\n",
    "#            valid(valid_loader)\n",
    "            print(\"\\n\")\n",
    "            \n",
    "        if epoch % 10 == 0:\n",
    "            lr /= 10\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch:  5\n",
      "TEST:\n",
      "Accuracy: 47.2%, Avg loss: 1.566535, torch metrics acc: 0.4724999964237213%\n",
      "\n",
      "\n",
      "Epoch:  10\n",
      "TEST:\n",
      "Accuracy: 63.1%, Avg loss: 1.013310, torch metrics acc: 0.6312500238418579%\n",
      "\n",
      "\n",
      "Epoch:  15\n",
      "TEST:\n",
      "Accuracy: 65.8%, Avg loss: 0.972509, torch metrics acc: 0.6581249833106995%\n",
      "\n",
      "\n",
      "Epoch:  20\n",
      "TEST:\n",
      "Accuracy: 66.6%, Avg loss: 0.935869, torch metrics acc: 0.6662499904632568%\n",
      "\n",
      "\n",
      "Epoch:  25\n",
      "TEST:\n",
      "Accuracy: 66.9%, Avg loss: 0.931921, torch metrics acc: 0.6693750023841858%\n",
      "\n",
      "\n",
      "Epoch:  30\n",
      "TEST:\n",
      "Accuracy: 67.2%, Avg loss: 0.927736, torch metrics acc: 0.671875%\n",
      "\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.10.6 64-bit ('cpu': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40517ded0b5017462b995be888d51a2e84ffa1c8a6e4cf94c222e6054af00f88"
   }
  },
  "interpreter": {
   "hash": "7731885e42f3b5ef5e7f85b92323b7ecd1cf85f8d8a102a156b6474dcda1e534"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}